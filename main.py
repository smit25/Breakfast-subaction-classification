# -*- coding: utf-8 -*-
"""NUS task.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oSi7XZYVgp2wtLKkv1ANEgDJ0Jz6GqNH
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# % cd drive/MyDrive/Breakfast
# % cd Breakfast

"""PREPROCESSING

"""

import os
import os.path
import torch
import numpy as np
import os.path
import pickle 
 

TRAINING_DATA_FILE = 'video_training_data.p'
TESTING_DATA_FILE = 'video_testing_data.p'
 
def _isArrayLike(obj):
    return hasattr(obj, '__iter__') and hasattr(obj, '__len__')

 
def load_data(split_load, actions_dict, GT_folder, DATA_folder, split_str):
    file_ptr = open(split_load, 'r')
    content_all = file_ptr.read().split('\n')[1:-1]
    content_all = [x.strip('./data/groundTruth/') + 't' for x in content_all]
    print(content_all[:10], ' groundTruth')
  
    all_tasks = ['tea', 'cereals', 'coffee', 'friedegg', 'juice', 'milk', 'sandwich', 'scrambledegg', 'pancake', 'salat']
  
    data_breakfast = []
    labels_breakfast = []
    tasks_breakfast = []
    b = False

    if split_str == 'train':
      data_breakfast_file = open(TRAINING_DATA_FILE, 'wb')
      segments_file = open('training_segment.txt', 'r')
      segment_ids = segments_file.read().split('\n')[:-1]

    if split_str == 'test':
      data_breakfast_file = open(TESTING_DATA_FILE, 'wb')
      segments_file = open('test_segment.txt', 'r')
      segment_ids = segments_file.read().split('\n')[:-1]
    
    #segments = []
    
    for idx, content in enumerate(content_all):
        if split == 'train' and idx > 1449: #1500
          break
        elif split == 'test' and idx > 199: #200
          break
        curr_task = content.split('_')[-1].split('.')[0]
        #print('curr_task: ', curr_task)
        tasks_breakfast.append(int( all_tasks.index(curr_task)) )
        #print('tasks_breakfast: ', tasks_breakfast[0])

        file_ptr = open( GT_folder + content, 'r')
        curr_gt = file_ptr.read().split('\n')[:-1]
        #print('curr_gt: ', curr_gt)
        label_seq, length_seq = get_label_length_seq(curr_gt)
        #print('label_seq: ', label_seq)
        #print('len_seq: ', length_seq)

        loc_curr_data = DATA_folder + os.path.splitext(content)[0] + '.gz'
        curr_data = np.loadtxt(loc_curr_data, dtype='float32')
        #print('curr_data: ', curr_data)

        label_curr_video = []
        for iik in range(len(curr_gt)):
            label_curr_video.append( actions_dict[curr_gt[iik]] )

        data_breakfast.append(torch.tensor(curr_data,  dtype=torch.float64 ) )
        labels_breakfast.append(label_curr_video )
        #print('data_break_shape: ', data_breakfast[0].shape)
        #print('label_break: ', labels_breakfast[0])

        video_segments = []

        curr_segment_ids = segment_ids[idx].split()
        for i in range(len(curr_segment_ids) - 1):
            start_segment_idx = int(curr_segment_ids[i])
            end_segment_idx = int(curr_segment_ids[i + 1])

            curr_segment_frames = curr_data[start_segment_idx:end_segment_idx]
            curr_segment_label = label_curr_video[start_segment_idx]
            video_segments.append((torch.tensor(curr_segment_frames, dtype=torch.float64), curr_segment_label))
        
        #segments.append(video_segments)
        pickle.dump(video_segments ,data_breakfast_file)
        print('[{}] {} contents dumped'.format(idx, content))
    data_breakfast_file.close()

    return data_breakfast, labels_breakfast, tasks_breakfast


def get_label_bounds( data_labels):
    labels_uniq = []
    labels_uniq_loc = []
    for kki in range(0, len(data_labels) ):
        uniq_group, indc_group = get_label_length_seq(data_labels[kki])
        labels_uniq.append(uniq_group)
        labels_uniq_loc.append(indc_group)
    return labels_uniq, labels_uniq_loc

def get_label_length_seq(content):
    label_seq = []
    length_seq = []
    start = 0
    length_seq.append(0)
    for i in range(len(content)):
        if content[i] != content[start]:
            label_seq.append(content[start])
            length_seq.append(i)
            start = i
    label_seq.append(content[start])
    length_seq.append(len(content))

    return label_seq, length_seq


def get_maxpool_lstm_data(cData, indices):
    list_data = []
    for kkl in range(len(indices)-1):
        cur_start = indices[kkl]
        cur_end = indices[kkl+1]
        if cur_end > cur_start:
            list_data.append(torch.max(cData[cur_start:cur_end,:],
                                       0)[0].squeeze(0))
        else:
            list_data.append(torch.max(cData[cur_start:cur_end+1,:],
                                       0)[0].squeeze(0))
    list_data  =  torch.stack(list_data)
    return list_data

def read_mapping_dict(mapping_file):
    file_ptr = open(mapping_file, 'r')
    actions = file_ptr.read().split('\n')[:-1]

    actions_dict=dict()
    for a in actions:
        actions_dict[a.split()[1]] = int(a.split()[0])

    return actions_dict


if __name__ == "__main__":
    split = 'train'
    COMP_PATH = ''
    
    train_split =  os.path.join(COMP_PATH, 'splits/train.split1.bundle')
    test_split  =  os.path.join(COMP_PATH, 'splits/test.split1.bundle')
    GT_folder   =  os.path.join(COMP_PATH, 'groundTruth/')
    DATA_folder =  os.path.join(COMP_PATH, 'data/')
    mapping_loc =  os.path.join(COMP_PATH, 'splits/mapping_bf.txt')

  
    actions_dict = read_mapping_dict(mapping_loc)

    data_feat, data_labels, tasks_labels = load_data(train_split, actions_dict, GT_folder, DATA_folder, split)
    #save_files(TRAINING_DATA_FILE)
    train_len = len(data_labels)
    print('train_len: ', train_len)
    

    split = 'test'

    data_feat, data_labels, tasks_labels= load_data(test_split, actions_dict, GT_folder, DATA_folder, split)
    test_len = len(data_labels)
    print('test_len: ', test_len)
    
    #save_files(TESTING_DATA_FILE)

import os
import os.path as path

def save_files(DATA_FILE):
    data_dir = DATA_FILE.split('.')[0]

    print("\n\n=====================================================")
    print("CREATING", DATA_FILE, "DIR")

    if not path.exists(data_dir):
        os.mkdir(data_dir)

    f = open(DATA_FILE, "rb")

    counter = 0
    while True:
        try:
            video = pickle.load(f)

            video_out = open(data_dir + '/' + str(counter) + '.p', 'wb')
            pickle.dump(video, video_out)
            video_out.close()

            if counter % 10 == 0:
                print('at sample: {}'.format(counter))

            counter += 1
        except (EOFError):
            break

    f.close()

save_files(TRAINING_DATA_FILE)

"""MODEL

"""

import torch
import torch.nn as nn
import torch.nn.functional as F
class ClassPredictor(nn.Module):
    def __init__(self, input_size, num_classes, drop_prob):
        super(ClassPredictor, self).__init__()
        
        self.input_dout = nn.Dropout(drop_prob) 
        
        hidden_1 = 240
        hidden_2 = 100        
        
        self.fc1 = nn.Linear(input_size, hidden_1)
        self.relu1 = nn.ReLU()
        self.dout1 = nn.Dropout(0.3)
        
        self.fc2 = nn.Linear(hidden_1, hidden_2)
        self.relu2 = nn.ReLU()
        
        self.out = nn.Linear(hidden_2, num_classes)
        
        nn.init.orthogonal_(self.fc1.weight).requires_grad_().cuda()
        nn.init.orthogonal_(self.fc2.weight).requires_grad_().cuda()
        nn.init.orthogonal_(self.out.weight).requires_grad_().cuda()

            
    def forward(self, x):
        # x: (input_size)
        x = self.input_dout(x)
        
        a1 = self.fc1(x)
        h1 = self.relu1(a1)
        dout1 = self.dout1(h1)

        a2 = self.fc2(dout1)
        h2 = self.relu2(a2)
        
        # y: (num_classes)
        y = self.out(h2)

        return y

class BiLSTMPool(nn.Module):
    def __init__(self, input_size, batch_size, hidden_size, device, num_classes, num_layers=1, drop_prob = 0.25):
        super(BiLSTMPool, self).__init__()
        self.batch_size = batch_size
        self.hidden_size = hidden_size
        self.embedd = embeddings

        #self.emb = nn.Embedding.from_pretrained(embeddings, freeze=False)
        self.lstm = nn.LSTM(bidirectional=True, input_size= input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)
        self.h0 = torch.randn(num_layers*2, batch_size, hidden_size).double().to(device)
        self.c0 = torch.randn(num_layers*2, batch_size, hidden_size).double().to(device)

        self.class_pred = ClassPredictor(input_size, num_classes, drop_prob)

    def forward(self, data, segment_indices):
        #sentence_embed = self.emb(sentence[0])
        #x_packed = pack_padded_sequence(data, lengths=sentence[1], batch_first=True, enforce_sorted=False)
        output, (hidden, _) = self.lstm(data, (self.h0, self.c0))

        # Use hidden states of each segment to predict their labels
        segment_outputs = []
        for (start, end) in segment_indices:
            hidden_states = out[:, start:end, :]

            """
            probs = nn.Softmax(dim=1)(out)
            print('PROBS: ', probs)
            preds = torch.max(probs, 1)[1]
            print('PREDS: ', preds)
            segment_outputs.append(preds)

            """
            
            # Compute the hidden state by doing max pooling over all time steps
            # pool_out: (hidden_size * 2)
            max_pool_out = F.adaptive_max_pool1d(hidden_states.permute(0,2,1), 1).squeeze()
            avg_pool_out = torch.mean(hidden_states, dim=1).squeeze()

            # concat_pool_out: (hidden_size * 2 * 2)
            concat_pool_out = torch.cat([max_pool_out, avg_pool_out])

            # output: (num_classes)
            output = self.class_pred(concat_pool_out)
            output = nn.Softmax(dim=1)(output)

            segment_outputs.append(output)

        # segment_outputs: (num_segments, num_classes)
        segment_outputs = torch.stack(segment_outputs)

        # output[output == 0] = -1e9
        # sent_hidden_pooled, _ = torch.max(output, dim=1)
        return segment_outputs


    def one_hot(sent, c):
      return torch.zeros(*sent.size(), c, device=device).scatter_(-1, sent.unsqueeze(-1), 1)
        

# ORIGINAL CODE FROM THE PAPER

"""
This file contains the definition of encoders used in https://arxiv.org/pdf/1705.02364.pdf
"""
"""
import numpy as np
import time

import torch
import torch.nn as nn


class InferSent(nn.Module):

    def __init__(self, config):
        super(InferSent, self).__init__()
        self.bsize = config['bsize']
        self.word_emb_dim = config['word_emb_dim']
        self.enc_lstm_dim = config['enc_lstm_dim']
        self.pool_type = config['pool_type']
        self.dpout_model = config['dpout_model']
        self.version = 1 if 'version' not in config else config['version']

        self.enc_lstm = nn.LSTM(self.word_emb_dim, self.enc_lstm_dim, 1,
                                bidirectional=True, dropout=self.dpout_model)

        assert self.version in [1, 2]
        if self.version == 1:
            self.bos = '<s>'
            self.eos = '</s>'
            self.max_pad = True
            self.moses_tok = False
        elif self.version == 2:
            self.bos = '<p>'
            self.eos = '</p>'
            self.max_pad = False
            self.moses_tok = True

    def is_cuda(self):
        # either all weights are on cpu or they are on gpu
        return self.enc_lstm.bias_hh_l0.data.is_cuda

    def forward(self, sent_tuple):
        # sent_len: [max_len, ..., min_len] (bsize)
        # sent: (seqlen x bsize x worddim)
        sent, sent_len = sent_tuple

        # Sort by length (keep idx)
        sent_len_sorted, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)
        sent_len_sorted = sent_len_sorted.copy()
        idx_unsort = np.argsort(idx_sort)

        idx_sort = torch.from_numpy(idx_sort).cuda() if self.is_cuda() \
            else torch.from_numpy(idx_sort)
        sent = sent.index_select(1, idx_sort)

        # Handling padding in Recurrent Networks
        sent_packed = nn.utils.rnn.pack_padded_sequence(sent, sent_len_sorted)
        sent_output = self.enc_lstm(sent_packed)[0]  # seqlen x batch x 2*nhid
        sent_output = nn.utils.rnn.pad_packed_sequence(sent_output)[0]

        # Un-sort by length
        idx_unsort = torch.from_numpy(idx_unsort).cuda() if self.is_cuda() \
            else torch.from_numpy(idx_unsort)
        sent_output = sent_output.index_select(1, idx_unsort)

        # Pooling
        if self.pool_type == "mean":
            sent_len = torch.FloatTensor(sent_len.copy()).unsqueeze(1).cuda()
            emb = torch.sum(sent_output, 0).squeeze(0)
            emb = emb / sent_len.expand_as(emb)
        elif self.pool_type == "max":
            if not self.max_pad:
                sent_output[sent_output == 0] = -1e9
            emb = torch.max(sent_output, 0)[0]
            if emb.ndimension() == 3:
                emb = emb.squeeze(0)
                assert emb.ndimension() == 2

        return emb

    def get_batch(self, batch):
        # sent in batch in decreasing order of lengths
        # batch: (bsize, max_len, word_dim)
        embed = np.zeros((len(batch[0]), len(batch), self.word_emb_dim))

        for i in range(len(batch)):
            for j in range(len(batch[i])):
                embed[j, i, :] = self.word_vec[batch[i][j]]

        return torch.FloatTensor(embed)
   
"""

"""LOADING THE DATASET"""

ROOT_DIR = "./"

DATA_DIR = ROOT_DIR
RESULTS_DIR = ROOT_DIR + "results/"

# Train - 1000 videos
# Test - 200 videos 

TRAINING_DATA = DATA_DIR + 'video_training_data/' 
TEST_DATA = DATA_DIR + "video_testing_data.p"

def get_next_video_data(f):    
    is_end_reached = False
    
    try:
        video = pickle.load(f) # [(segment, label), ...]
    except (EOFError):
        is_end_reached = True
        return [], is_end_reached
    
    return video, is_end_reached

def get_video_data(idx, input_path): 
    train_video_f = open(input_path + str(idx) + '.p', 'rb') 
    video = pickle.load(train_video_f) # [(segment, label), ...]
    train_video_f.close()


    return video

"""CONVERT DATA TO INPUT

"""

def transform_to_inputs(video):
    segments = [] # segments (list of frames) in the video
    labels = [] # labels of each segment
    segment_indices = []
    offset = 0
    for segment_num in range(len(video)):
        segments.append(video[segment_num][0])
        labels.append(video[segment_num][1])
        segment_indices.append((offset, offset + video[segment_num][0].shape[0]))

        offset += video[segment_num][0].shape[0]
        
    # Load frames as tensors with gradient accumulation abilities
    input_frames = torch.cat(segments, 0).unsqueeze(0).requires_grad_().cuda() # unsqueeze to add batch dim
    labels = torch.Tensor(labels).long().cuda()
    segment_indices = torch.IntTensor(segment_indices).cuda()
    
    return input_frames, labels, segment_indices

"""DATALOADER"""

import torch
import torch.utils.data as data
import numpy as np

class Dataloader(data.Dataset):
  def __init__(self, input_file, count, should_shuffle = True):
    super(Dataloader).__init__()

    self.count = count - 1
    self.video_idxs = np.arange(count)
    if should_shuffle:
        np.random.shuffle(self.video_idxs)

    self.input_l = []
    self.label_l = []
    self.segment_l = []

    print('video_idxs: ', self.video_idxs)
    for idx in self.video_idxs:
      video = get_video_data(idx, input_file)
      inputs, labels, segment_indices = transform_to_inputs(video)
      self.input_l.append(inputs)
      self.label_l.append(labels)
      self.segment_l.append(segment_indices)
   

  def __len__(self):
    return (self.count)
    
  def __getitem__(self, id):
    return (self.input_l[id], self.label_l[id], self.segment_l[id])
    
  def normalize(self, buffer):
    for i, frame in enumerate(buffer):
      frame -= np.array([[[90.0, 98.0, 102.0]]])
      buffer[i] = frame

    return buffer

! pip install tensorBoardX

"""TRAIN AND TEST"""

import torchvision
import torch
import torch.nn as nn
import torch.optim as optim
import torch.utils.data as Data
from tensorboardX import SummaryWriter
import torch.utils.data as Data
import os
from tqdm import tqdm
from torch.autograd import Variable

"""
To view the data written by tensorboardX
tensorboard --logdir <path of logs directory>
In my case, pathdir = 'logs/'
"""

train_len = 1450
test_len = 200

def init_weights(model):
    for name, param in model.named_parameters():
        nn.init.uniform_(param.data, -0.08, 0.08)

def accuracy_fn(pred, label):
    return (pred.argmax(dim=1) == label).float().mean().item()

def train():
  data = Dataloader(TRAINING_DATA, train_len)
  print('Dataloader successful!')
  logger = SummaryWriter(os.path.join(LOG_DIR,'-summary'))
  
  opt = {
    'epochs': 2,
    'layers':1,
    'batch_size':16,
    'input_dim':400,
    'hidden_dim':160,
    'out_dim':48,
    'num_classes':48,
    'embed':100,
    'lr': 0.01,
  }
  
  model = BiLSTMPool(opt['input_dim'], opt['batch_size'], opt['hidden_dim'], device, opt['layers'])
  
  train_loader = Data.DataLoader(
        Data.Subset(data, range(train_len-1)),
        batch_size=opt['batch_size'],
        shuffle=True,
  )
  print('TRAIN_LOADED')
  
  model.apply(init_weights)
  optimizer = optim.Adam(model.parameters(), lr = opt['lr'])
  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)
  
  model.to(device)
  criterion = nn.CrossEntropyLoss(ignore_index=None).to(device)
  
  print('--------------------TRAIN---------------------')
  
  for epoch in range(opt['epochs']):
    itr = 0
    scheduler.step()
    model.train()
    running_loss = 0
    running_corrects = 0

    for inputs,labels, segment_indices in tqdm(train_loader, ascii = True, desc = 'train' + str(epoch+1)):
      inputs = Variable(inputs, requires_grad=True).to(device)
      labels = Variable(labels).to(device)
      segment_indices = Variable(segment_indices).to(device)
      
      optimizer.zero_grad()
      preds = model(inputs, segment_indices)
      
      loss = criterion(preds, labels)
      
      loss.backward()
      optimizer.step()
      
      #_, predicted = torch.max(outputs.data, 1)
      running_loss += loss.item() * inputs.size(0)
      running_corrects += torch.sum(preds == labels.data)
    
    epoch_loss = running_loss / train_len
    epoch_accur = running_corrects.double() / train_len
      
    logger.add_scalar('train_loss_epoch', epoch_loss, epoch)
    logger.add_scalar('train_acc_epoch', epoch_accur, epoch)

    itr +=1
    
  #Save model
  torch.save(model)
  torch.cuda.empty_cache()
  logger.close()
  
  print('--------------------TEST----------------------')

  data = Dataloader(TEST_DATA, test_len)
  test_loader = Data.Dataloader(Data.Subset(data, range(test_len -1)),
        batch_size=opt['batch_size'],
        shuffle=True,)
  
  accu = []
  losses = []
  model.eval()
  y = {'Actual': [], 'Predicted': []}
  with torch.no_grad():
    for inputs, labels, segment_indices in tqdm(test_loader, ascii = True, desc = 'Test'):
      inputs = Variable(inputs, requires_grad = False).to(device)
      output = model(inputs).to(device)
      
      probs = nn.Softmax(dim=1)(output)
      preds = torch.max(probs, 1)[1]
      losses = criterion(preds, labels)
      
      accuracy.append(accuracy_fn(preds, labels))
      losses.append(losses.item())

      y['Actual'].extend(labels.tolist())
      y['Predicted'].extend(preds.tolist())
  
  torch.cuda.empty_cache()
  final_acc = np.mean(accuracy)
  final_loss = np.mean(losses)
  return final_acc, final_loss, y
      
  
if __name__ == '__main__':
  LOG_DIR = 'logs'
  HOME = './'
  device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
  test_accuracy, test_loss, y = train()
  print(test_accuracy)

from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, roc_auc_score

print('\nMacro f1 Score= %.4f' % f1_score(y['Actual'], y['Predicted'], average="macro"))
print('Macro Precision= %.4f' % precision_score(y['Actual'], y['Predicted'], zero_division=0, average="macro"))
print('Macro Recall= %.4f' % recall_score(y['Actual'], y['Predicted'], average="macro")) 

print('\nMicro f1 Score= %.4f' % f1_score(y['Actual'], y['Predicted'], average="micro"))
print('Micro Precision= %.4f' % precision_score(y['Actual'], y['Predicted'], zero_division=0, average="micro"))
print('Micro Recall= %.4f' % recall_score(y['Actual'], y['Predicted'], average="micro")) 

print('\nAccuracy: %.4f' % accuracy_score(y['Actual'], y['Predicted']))